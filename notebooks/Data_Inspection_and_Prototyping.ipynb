{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1749880701373,
     "user": {
      "displayName": "Yash Thube",
      "userId": "10504705849094262932"
     },
     "user_tz": -330
    },
    "id": "vSbDAMjMtUy0",
    "outputId": "e63853d2-9ad3-47f6-a08e-dfbb99b8dd5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up VSR-style dataset for spatial reasoning...\n",
      "Dataset created successfully!\n",
      "Train examples: 10\n",
      "Test examples: 5\n",
      "\n",
      "Dataset structure:\n",
      "Keys: ['train', 'test']\n",
      "\n",
      "Sample examples:\n",
      "\n",
      "Example 1:\n",
      "  image: image_001.jpg\n",
      "  caption: The red ball is to the left of the blue box.\n",
      "  label: 1\n",
      "  spatial_relation: left\n",
      "\n",
      "Example 2:\n",
      "  image: image_002.jpg\n",
      "  caption: The cat is sitting above the mat on the floor.\n",
      "  label: 1\n",
      "  spatial_relation: above\n",
      "\n",
      "Example 3:\n",
      "  image: image_003.jpg\n",
      "  caption: The car is parked behind the large tree.\n",
      "  label: 1\n",
      "  spatial_relation: behind\n",
      "\n",
      "==================================================\n",
      "VSR-style dataset is ready for spatial perturbation testing!\n",
      "You can now use: vsr_dataset['train'][0]['caption']\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "print(\"Setting up VSR-style dataset for spatial reasoning...\")\n",
    "\n",
    "vsr_sample_data = [\n",
    "    {\n",
    "        'image': 'image_001.jpg',\n",
    "        'caption': 'The red ball is to the left of the blue box.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'left'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_002.jpg',\n",
    "        'caption': 'The cat is sitting above the mat on the floor.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'above'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_003.jpg',\n",
    "        'caption': 'The car is parked behind the large tree.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'behind'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_004.jpg',\n",
    "        'caption': 'The bird is perched at the top of the building.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'top'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_005.jpg',\n",
    "        'caption': 'The book is placed below the computer monitor.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'below'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_006.jpg',\n",
    "        'caption': 'The dog is standing in front of the house door.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'in front of'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_007.jpg',\n",
    "        'caption': 'The flower pot is positioned to the right of the window.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'right'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_008.jpg',\n",
    "        'caption': 'The lamp is at the bottom of the staircase.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'bottom'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_009.jpg',\n",
    "        'caption': 'The picture frame is above the fireplace and to the left of the clock.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'above_left'\n",
    "    },\n",
    "    {\n",
    "        'image': 'image_010.jpg',\n",
    "        'caption': 'The coffee cup is on the table, in front of the laptop.',\n",
    "        'label': 1,\n",
    "        'spatial_relation': 'in front of'\n",
    "    }\n",
    "]\n",
    "\n",
    "vsr_dataset = {\n",
    "    'train': vsr_sample_data,\n",
    "    'test': vsr_sample_data[:5]  \n",
    "}\n",
    "\n",
    "print(f\"Dataset created successfully!\")\n",
    "print(f\"Train examples: {len(vsr_dataset['train'])}\")\n",
    "print(f\"Test examples: {len(vsr_dataset['test'])}\")\n",
    "\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(f\"Keys: {list(vsr_dataset.keys())}\")\n",
    "\n",
    "print(f\"\\nSample examples:\")\n",
    "for i in range(3):\n",
    "    example = vsr_dataset['train'][i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    for key, value in example.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"VSR-style dataset is ready for spatial perturbation testing!\")\n",
    "print(\"You can now use: vsr_dataset['train'][0]['caption']\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1749880868847,
     "user": {
      "displayName": "Yash Thube",
      "userId": "10504705849094262932"
     },
     "user_tz": -330
    },
    "id": "XrYWZznnt6GX",
    "outputId": "24aeaa33-0dc7-4715-fb43-29d955c248a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Spatial Word Perturbation Test ===\n",
      "\n",
      "Test 1:\n",
      "Original:   The cat is to the left of the dog.\n",
      "Perturbed:  The cat is to the right of the dog.\n",
      "\n",
      "Test 2:\n",
      "Original:   The book is above the table and below the shelf.\n",
      "Perturbed:  The book is below the table and above the shelf.\n",
      "\n",
      "Test 3:\n",
      "Original:   The car is in front of the house.\n",
      "Perturbed:  The car is behind the house.\n",
      "\n",
      "Test 4:\n",
      "Original:   The bird is at the top of the tree.\n",
      "Perturbed:  The bird is at the bottom of the tree.\n",
      "\n",
      "Test 5:\n",
      "Original:   Turn right at the corner, then go left.\n",
      "Perturbed:  Turn left at the corner, then go right.\n",
      "\n",
      "Test 6:\n",
      "Original:   The ball is behind the chair and above the floor.\n",
      "Perturbed:  The ball is in front of the chair and below\n",
      "\n",
      "Test 7:\n",
      "Original:   In front of the building, there is a tree on the left side.\n",
      "Perturbed:  Behind the building, there is a tree on the right side.\n",
      "\n",
      "=== Example with VSR Dataset ===\n",
      "To use with VSR dataset caption:\n",
      "perturbed_caption = perturb_spatial_words(vsr_dataset['train'][0]['caption'])\n",
      "\n",
      "This function is ready to be applied to any caption from the VSR dataset!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def perturb_spatial_words(sentence):\n",
    "    \"\"\"\n",
    "    Perturbs spatial words in a sentence by swapping them with their opposites.\n",
    "\n",
    "    Swaps:\n",
    "    - left ↔ right\n",
    "    - above ↔ below\n",
    "    - top ↔ bottom\n",
    "    - in front of ↔ behind\n",
    "\n",
    "    Args:\n",
    "        sentence (str): Input sentence containing spatial descriptions\n",
    "\n",
    "    Returns:\n",
    "        str: Sentence with spatial words swapped\n",
    "    \"\"\"\n",
    "\n",
    "    spatial_swaps = {\n",
    "        'left': 'right',\n",
    "        'right': 'left',\n",
    "        'above': 'below',\n",
    "        'below': 'above',\n",
    "        'top': 'bottom',\n",
    "        'bottom': 'top',\n",
    "        'in front of': 'behind',\n",
    "        'behind': 'in front of'\n",
    "    }\n",
    "\n",
    "    perturbed_sentence = sentence.lower()\n",
    "\n",
    "    for original, replacement in spatial_swaps.items():\n",
    "        if len(original.split()) > 1: \n",
    "           \n",
    "            pattern = r'\\b' + re.escape(original) + r'\\b'\n",
    "            perturbed_sentence = re.sub(pattern, f\"__TEMP_{replacement.replace(' ', '_')}__\",\n",
    "                                     perturbed_sentence, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "    for original, replacement in spatial_swaps.items():\n",
    "        if len(original.split()) == 1: \n",
    "            pattern = r'\\b' + re.escape(original) + r'\\b'\n",
    "            perturbed_sentence = re.sub(pattern, f\"__TEMP_{replacement}__\",\n",
    "                                     perturbed_sentence, flags=re.IGNORECASE)\n",
    "\n",
    "    perturbed_sentence = re.sub(r'__TEMP_([^_]+(?:_[^_]+)*)__',\n",
    "                               lambda m: m.group(1).replace('_', ' '),\n",
    "                               perturbed_sentence)\n",
    "\n",
    "    words_original = sentence.split()\n",
    "    words_perturbed = perturbed_sentence.split()\n",
    "\n",
    "    final_words = []\n",
    "    for i, (orig, pert) in enumerate(zip(words_original, words_perturbed)):\n",
    "        if orig.isupper():\n",
    "            final_words.append(pert.upper())\n",
    "        elif orig.istitle():\n",
    "            final_words.append(pert.capitalize())\n",
    "        else:\n",
    "            final_words.append(pert)\n",
    "\n",
    "    return ' '.join(final_words)\n",
    "\n",
    "def test_perturbation():\n",
    "    \"\"\"Test the perturbation function with various examples\"\"\"\n",
    "\n",
    "    test_sentences = [\n",
    "        \"The cat is to the left of the dog.\",\n",
    "        \"The book is above the table and below the shelf.\",\n",
    "        \"The car is in front of the house.\",\n",
    "        \"The bird is at the top of the tree.\",\n",
    "        \"Turn right at the corner, then go left.\",\n",
    "        \"The ball is behind the chair and above the floor.\",\n",
    "        \"In front of the building, there is a tree on the left side.\"\n",
    "    ]\n",
    "\n",
    "    print(\"=== Spatial Word Perturbation Test ===\\n\")\n",
    "\n",
    "    for i, sentence in enumerate(test_sentences, 1):\n",
    "        perturbed = perturb_spatial_words(sentence)\n",
    "        print(f\"Test {i}:\")\n",
    "        print(f\"Original:   {sentence}\")\n",
    "        print(f\"Perturbed:  {perturbed}\")\n",
    "        print()\n",
    "\n",
    "test_perturbation()\n",
    "\n",
    "print(\"=== Example with VSR Dataset ===\")\n",
    "print(\"To use with VSR dataset caption:\")\n",
    "print(\"perturbed_caption = perturb_spatial_words(vsr_dataset['train'][0]['caption'])\")\n",
    "print(\"\\nThis function is ready to be applied to any caption from the VSR dataset!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMXSf/eX3KD8tDmE51UGQAs",
   "gpuType": "T4",
   "mount_file_id": "1gqg9ejWQtTK1dGFIIrk-yXxRRG7zZvJy",
   "provenance": [
    {
     "file_id": "1gqg9ejWQtTK1dGFIIrk-yXxRRG7zZvJy",
     "timestamp": 1749880908838
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
